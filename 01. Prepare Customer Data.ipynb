{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data\n",
    "## Install Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 5.4 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting urllib3<1.25,>=1.21.1\n",
      "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (4.44.1)\n",
      "Collecting python-slugify\n",
      "  Downloading python-slugify-4.0.1.tar.gz (11 kB)\n",
      "Collecting slugify\n",
      "  Downloading slugify-0.0.1.tar.gz (1.2 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->kaggle) (2.9)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify, slugify\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73274 sha256=6415a396e7b60a7bd14977350de6228cef55068fd5df63227ee670c81bc5a08a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/cf/aa/f0/ed1179bbcd729b29d0dfda59826fb3b55f0a4a0c3f713c1c82\n",
      "  Building wheel for python-slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-slugify: filename=python_slugify-4.0.1-py2.py3-none-any.whl size=6767 sha256=68909f4a83dbda6174a92e8a1c3212f2fc00bda856ef6476556e150b3677be6d\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/72/e6/db/122611605e60148f54ee2abaca98b2bbeafc6e22486a867bad\n",
      "  Building wheel for slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for slugify: filename=slugify-0.0.1-py3-none-any.whl size=1908 sha256=4be3dc4e013505590ead3ad2854a25b718563e9d887c234e3240539b0c1f202a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/7d/51/b0/c584cbdd0a8fc685d68677e58cde93814cbbc7fd9867fb5fe6\n",
      "Successfully built kaggle python-slugify slugify\n",
      "Installing collected packages: urllib3, text-unidecode, python-slugify, slugify, kaggle\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.8\n",
      "    Uninstalling urllib3-1.25.8:\n",
      "      Successfully uninstalled urllib3-1.25.8\n",
      "Successfully installed kaggle-1.5.8 python-slugify-4.0.1 slugify-0.0.1 text-unidecode-1.3 urllib3-1.24.3\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Settings\n",
    "\n",
    "Before running the kaggle download, kaggle configurations should saved locally in the notebook using a terminal prompt. \n",
    "```\n",
    "sh-4.2$ history\n",
    "sh-4.2$ mkdir ~/.kaggle\n",
    "sh-4.2$ vi kaggle.json //add the kaggle credentials\n",
    "sh-4.2$ mv kaggle.json ~/.kaggle/kaggle.json\n",
    "sh-4.2$ chmod 600 ~/.kaggle/kaggle.json\n",
    "sh-4.2$ kaggle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading bank-marketing-dataset.zip to /home/ec2-user/SageMaker/amazon-personalize\r\n",
      "\r",
      "  0%|                                                | 0.00/142k [00:00<?, ?B/s]\r\n",
      "\r",
      "100%|████████████████████████████████████████| 142k/142k [00:00<00:00, 20.9MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download --force  janiobachmann/bank-marketing-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  bank-marketing-dataset.zip\n",
      "  inflating: bank.csv                \n"
     ]
    }
   ],
   "source": [
    "!unzip bank-marketing-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Customer Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11162 entries, 0 to 11161\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        11162 non-null  int64 \n",
      " 1   job        11162 non-null  object\n",
      " 2   marital    11162 non-null  object\n",
      " 3   education  11162 non-null  object\n",
      " 4   default    11162 non-null  object\n",
      " 5   balance    11162 non-null  int64 \n",
      " 6   housing    11162 non-null  object\n",
      " 7   loan       11162 non-null  object\n",
      " 8   contact    11162 non-null  object\n",
      " 9   day        11162 non-null  int64 \n",
      " 10  month      11162 non-null  object\n",
      " 11  duration   11162 non-null  int64 \n",
      " 12  campaign   11162 non-null  int64 \n",
      " 13  pdays      11162 non-null  int64 \n",
      " 14  previous   11162 non-null  int64 \n",
      " 15  poutcome   11162 non-null  object\n",
      " 16  deposit    11162 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"bank.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a unique customer ID to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>deposit</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30908</td>\n",
       "      <td>yes</td>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30909</td>\n",
       "      <td>yes</td>\n",
       "      <td>56</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30910</td>\n",
       "      <td>yes</td>\n",
       "      <td>41</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30911</td>\n",
       "      <td>yes</td>\n",
       "      <td>55</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30912</td>\n",
       "      <td>yes</td>\n",
       "      <td>54</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID deposit  age         job  marital  education\n",
       "0    30908     yes   59      admin.  married  secondary\n",
       "1    30909     yes   56      admin.  married  secondary\n",
       "2    30910     yes   41  technician  married  secondary\n",
       "3    30911     yes   55    services  married  secondary\n",
       "4    30912     yes   54      admin.  married   tertiary"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['USER_ID'] = np.arange(len(df))+30908\n",
    "# cols = df.columns.tolist()\n",
    "# cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "## max 5 user attributes, get rid of some columns not very useful \n",
    "df_custmer = df[['USER_ID','deposit','age', 'job','marital','education']]\n",
    "df_custmer.to_csv('customer11k.csv')\n",
    "df_custmer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket ='personalize-custdata'      # replace with the name of your S3 bucket\n",
    "filename ='customer11k.csv'\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema for customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"schemaArn\": \"arn:aws:personalize:ap-southeast-1:248025046818:schema/personalize-customer-schema\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"9a926beb-c05c-4083-bbe9-c0979e7e000c\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Sun, 06 Sep 2020 13:27:08 GMT\",\n",
      "      \"x-amzn-requestid\": \"9a926beb-c05c-4083-bbe9-c0979e7e000c\",\n",
      "      \"content-length\": \"98\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "customer_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Users\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"deposit\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"age\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"job\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"marital\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"education\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-customer-schema\",\n",
    "    schema = json.dumps(customer_schema)\n",
    ")\n",
    "\n",
    "customer_schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Interactions Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            USER_ID       ITEM_ID     TIMESTAMP\n",
      "count  23969.000000  23969.000000  2.396900e+04\n",
      "mean   36377.740123      4.724728  1.568092e+09\n",
      "std     3173.550875      2.855511  9.203915e+06\n",
      "min    30908.000000      0.000000  1.551572e+09\n",
      "25%    33608.000000      3.000000  1.560049e+09\n",
      "50%    36375.000000      5.000000  1.568023e+09\n",
      "75%    39160.000000      7.000000  1.576135e+09\n",
      "max    41908.000000      9.000000  1.585917e+09\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35873</td>\n",
       "      <td>5</td>\n",
       "      <td>1578556273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35873</td>\n",
       "      <td>3</td>\n",
       "      <td>1578604177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35873</td>\n",
       "      <td>9</td>\n",
       "      <td>1579509607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31950</td>\n",
       "      <td>3</td>\n",
       "      <td>1580779928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31950</td>\n",
       "      <td>3</td>\n",
       "      <td>1581746466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31950</td>\n",
       "      <td>8</td>\n",
       "      <td>1582464100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31950</td>\n",
       "      <td>7</td>\n",
       "      <td>1582649990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38544</td>\n",
       "      <td>7</td>\n",
       "      <td>1569982368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39338</td>\n",
       "      <td>6</td>\n",
       "      <td>1561972882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39338</td>\n",
       "      <td>0</td>\n",
       "      <td>1562581877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39338</td>\n",
       "      <td>0</td>\n",
       "      <td>1563611766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39338</td>\n",
       "      <td>5</td>\n",
       "      <td>1563901054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39338</td>\n",
       "      <td>4</td>\n",
       "      <td>1564588884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32606</td>\n",
       "      <td>4</td>\n",
       "      <td>1559912850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32606</td>\n",
       "      <td>9</td>\n",
       "      <td>1560020641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32606</td>\n",
       "      <td>7</td>\n",
       "      <td>1560911308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32606</td>\n",
       "      <td>6</td>\n",
       "      <td>1560949164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32606</td>\n",
       "      <td>0</td>\n",
       "      <td>1561499145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36355</td>\n",
       "      <td>8</td>\n",
       "      <td>1556905121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>36355</td>\n",
       "      <td>2</td>\n",
       "      <td>1557135713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    USER_ID  ITEM_ID   TIMESTAMP\n",
       "0     35873        5  1578556273\n",
       "1     35873        3  1578604177\n",
       "2     35873        9  1579509607\n",
       "3     31950        3  1580779928\n",
       "4     31950        3  1581746466\n",
       "5     31950        8  1582464100\n",
       "6     31950        7  1582649990\n",
       "7     38544        7  1569982368\n",
       "8     39338        6  1561972882\n",
       "9     39338        0  1562581877\n",
       "10    39338        0  1563611766\n",
       "11    39338        5  1563901054\n",
       "12    39338        4  1564588884\n",
       "13    32606        4  1559912850\n",
       "14    32606        9  1560020641\n",
       "15    32606        7  1560911308\n",
       "16    32606        6  1560949164\n",
       "17    32606        0  1561499145\n",
       "18    36355        8  1556905121\n",
       "19    36355        2  1557135713"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import time\n",
    "from calendar import monthrange\n",
    "from random import seed\n",
    "from random import randint\n",
    "import numpy as np\n",
    "#import platform\n",
    "# print(platform.python_version())\n",
    "\n",
    "\n",
    "###################\n",
    "## Declare constants \n",
    "###################\n",
    "# customer ID start\n",
    "starting_cust_id=30908\n",
    "\n",
    "# customer ID end\n",
    "ending_cust_id=30908+11000\n",
    "\n",
    "# how many evemts we need?\n",
    "max_interactions_sequence_count=8000\n",
    "\n",
    "# starting date of the dataset\n",
    "event_start_date = datetime(2019, 3, 3)\n",
    "# datetime.datetime.utcfromtimestamp(0)\n",
    "epoch_event_start_date = int(event_start_date.strftime('%s'))\n",
    "# print(epoch_event_start_date)\n",
    "\n",
    "event_time_range = 31536000 #seconds in a year. \n",
    "\n",
    "max_time_between_events = 1059200  \n",
    "min_time_between_events = 3900 # 3 days. \n",
    "\n",
    "\n",
    "# set of possible interactions \n",
    "# Lets say there are 10 different types of events. \n",
    "# this array defines a few set of interaction sequence \n",
    "# we will use these fixed set of interaction sequence to generate synthetic data\n",
    "array = np.arange(10)\n",
    "newarray = np.repeat(array, 3)\n",
    "np.random.shuffle(newarray)\n",
    "\n",
    "interaction_sequence_length = 5\n",
    "number_different_interaction_sequences=6\n",
    "interaction_array = newarray.reshape(number_different_interaction_sequences,interaction_sequence_length)\n",
    "\n",
    "\n",
    "\n",
    "#data column headers \n",
    "# USER_ID (string), ITEM_ID (string), TIMESTAMP (long), IMPRESSION\n",
    "\n",
    "\n",
    "with open('interactions.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerow([\"USER_ID\", \"ITEM_ID\", \"TIMESTAMP\"])\n",
    "\n",
    "    ## Loop for interaction sequences \n",
    "    interactions_sequence_count=0 \n",
    "    while ( interactions_sequence_count <= max_interactions_sequence_count ):\n",
    "\n",
    "        #pic a customer id randomly \n",
    "        customer_id = randint(starting_cust_id, ending_cust_id)\n",
    "\n",
    "        #pic a event sequence randomly \n",
    "        sequence_id =  randint(0, number_different_interaction_sequences-1)\n",
    "\n",
    "        # select a event sequence length \n",
    "        max_sequence_length = randint(0, interaction_sequence_length-1)\n",
    "\n",
    "        sequence_length = 0\n",
    "        time_lapse_between_event = epoch_event_start_date+event_time_range\n",
    "        next_event_time =randint(epoch_event_start_date , time_lapse_between_event)\n",
    "        \n",
    "        # Loop for generating individual interaction events within a sequence\n",
    "        while (sequence_length <= max_sequence_length):\n",
    "            writer.writerow([customer_id, interaction_array[sequence_id][sequence_length], next_event_time])\n",
    "            sequence_length+=1\n",
    "            next_event_time += randint(min_time_between_events, max_time_between_events)\n",
    "\n",
    "        interactions_sequence_count+=1\n",
    "\n",
    "file.close()\n",
    "\n",
    "interactions_df=pd.read_csv(\"interactions.csv\")\n",
    "print(interactions_df.describe())\n",
    "interactions_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the interactions data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket ='personalize-custdata'      # replace with the name of your S3 bucket\n",
    "filename ='interactions.csv'\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a schema definition in Amazon Personalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceAlreadyExistsException",
     "evalue": "An error occurred (ResourceAlreadyExistsException) when calling the CreateSchema operation: Another resource with Arn arn:aws:personalize:ap-southeast-1:248025046818:schema/personalize-intertactions-schema already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceAlreadyExistsException\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-f84c216f2990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m create_schema_response = personalize.create_schema(\n\u001b[1;32m     23\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"personalize-intertactions-schema\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceAlreadyExistsException\u001b[0m: An error occurred (ResourceAlreadyExistsException) when calling the CreateSchema operation: Another resource with Arn arn:aws:personalize:ap-southeast-1:248025046818:schema/personalize-intertactions-schema already exists."
     ]
    }
   ],
   "source": [
    "interactions_schema =  {\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"Interactions\",\n",
    "  \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "  \"fields\": [\n",
    "      {\n",
    "          \"name\": \"USER_ID\",\n",
    "          \"type\": \"string\"\n",
    "      },\n",
    "      {\n",
    "          \"name\": \"ITEM_ID\",\n",
    "          \"type\": \"string\"\n",
    "      },\n",
    "      {\n",
    "          \"name\": \"TIMESTAMP\",\n",
    "          \"type\": \"long\"\n",
    "      }\n",
    "  ],\n",
    "  \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-intertactions-schema\",\n",
    "    schema = json.dumps(interactions_schema)\n",
    ")\n",
    "\n",
    "interactions_schema_arn = create_schema_response['schemaArn']\n",
    "\n",
    "print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Createa a dataset group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetGroupArn\": \"arn:aws:personalize:ap-southeast-1:248025046818:dataset-group/personalize-demo-dataset\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"d1fe52be-da51-4299-acb2-f7a2b0de2889\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 07 Sep 2020 09:07:10 GMT\",\n",
      "      \"x-amzn-requestid\": \"d1fe52be-da51-4299-acb2-f7a2b0de2889\",\n",
      "      \"content-length\": \"108\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"personalize-demo-dataset\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetGroup: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DELTE THIS BLOCK LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.list_schemas()\n",
    "interactions_schema_arn = 'arn:aws:personalize:ap-southeast-1:248025046818:schema/personalize-intertactions-schema'\n",
    "customer_schema_arn = 'arn:aws:personalize:ap-southeast-1:248025046818:schema/personalize-customer-schema'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetArn\": \"arn:aws:personalize:ap-southeast-1:248025046818:dataset/personalize-demo-dataset/INTERACTIONS\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"2186a438-8dfb-4945-acae-6faba1477892\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 07 Sep 2020 09:26:42 GMT\",\n",
      "      \"x-amzn-requestid\": \"2186a438-8dfb-4945-acae-6faba1477892\",\n",
      "      \"content-length\": \"110\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = interactions_schema_arn,\n",
    "    name = \"demo-dataset\"\n",
    ")\n",
    "\n",
    "interactions_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetArn\": \"arn:aws:personalize:ap-southeast-1:248025046818:dataset/personalize-demo-dataset/USERS\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"dd9f135e-a947-40d2-b5af-d917691d2a23\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 07 Sep 2020 09:28:06 GMT\",\n",
      "      \"x-amzn-requestid\": \"dd9f135e-a947-40d2-b5af-d917691d2a23\",\n",
      "      \"content-length\": \"103\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataset_type = \"USERS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = customer_schema_arn,\n",
    "    name = \"demo-interection-dataset\"\n",
    ")\n",
    "\n",
    "CUSTOMER_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Import Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetImportJobArn\": \"arn:aws:personalize:ap-southeast-1:248025046818:dataset-import-job/interactions-dataset-import-job\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"572d5e7b-4ac0-4435-9628-faf7e2671412\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 07 Sep 2020 09:40:25 GMT\",\n",
      "      \"x-amzn-requestid\": \"572d5e7b-4ac0-4435-9628-faf7e2671412\",\n",
      "      \"content-length\": \"124\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "role_arn = 'arn:aws:iam::248025046818:role/AmazonPersonalizeRole'\n",
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"interactions-dataset-import-job\",\n",
    "    datasetArn = interactions_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket, 'interactions.csv')\n",
    "        \n",
    "    }, roleArn = role_arn\n",
    ")\n",
    "\n",
    "interactions_dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetImportJobArn\": \"arn:aws:personalize:ap-southeast-1:248025046818:dataset-import-job/user-dataset-import-job\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"4708054d-7e9b-4923-8ae8-48b91da9c56c\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 07 Sep 2020 09:42:07 GMT\",\n",
      "      \"x-amzn-requestid\": \"4708054d-7e9b-4923-8ae8-48b91da9c56c\",\n",
      "      \"content-length\": \"116\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "role_arn = 'arn:aws:iam::248025046818:role/AmazonPersonalizeRole'\n",
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"user-dataset-import-job\",\n",
    "    datasetArn = CUSTOMER_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket, 'customer11k.csv')\n",
    "        \n",
    "    }, roleArn = role_arn\n",
    ")\n",
    "\n",
    "users_dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.list_dataset_import_jobs()\n",
    "interactions_dataset_import_job_arn = 'arn:aws:personalize:ap-southeast-1:248025046818:dataset-import-job/interactions-dataset-import-job'\n",
    "users_dataset_import_job_arn ='arn:aws:personalize:ap-southeast-1:248025046818:dataset-import-job/user-dataset-import-job'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetImportJob: CREATE FAILED\n"
     ]
    }
   ],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = users_dataset_import_job_arn\n",
    "    )\n",
    "    \n",
    "    dataset_import_job = describe_dataset_import_job_response[\"datasetImportJob\"]\n",
    "    if \"latestDatasetImportJobRun\" not in dataset_import_job:\n",
    "        status = dataset_import_job[\"status\"]\n",
    "        print(\"DatasetImportJob: {}\".format(status))\n",
    "    else:\n",
    "        status = dataset_import_job[\"latestDatasetImportJobRun\"][\"status\"]\n",
    "        print(\"LatestDatasetImportJobRun: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jobName': 'interactions-dataset-import-job', 'datasetImportJobArn': 'arn:aws:personalize:ap-southeast-1:248025046818:dataset-import-job/interactions-dataset-import-job', 'datasetArn': 'arn:aws:personalize:ap-southeast-1:248025046818:dataset/personalize-demo-dataset/INTERACTIONS', 'dataSource': {'dataLocation': 's3://personalize-custdata/interactions.csv'}, 'roleArn': 'arn:aws:iam::248025046818:role/AmazonPersonalizeRole', 'status': 'CREATE FAILED', 'creationDateTime': datetime.datetime(2020, 9, 7, 9, 40, 26, 234000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2020, 9, 7, 9, 40, 55, 68000, tzinfo=tzlocal()), 'failureReason': 'Insufficient privileges for accessing data in S3. Please look at https://docs.aws.amazon.com/personalize/latest/dg/getting-started.html#gs-upload-to-bucket and fix bucket policy on personalize-custdata.'}\n",
      "DatasetImportJob: CREATE FAILED\n"
     ]
    }
   ],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = interactions_dataset_import_job_arn\n",
    "    )\n",
    "    \n",
    "    dataset_import_job = describe_dataset_import_job_response[\"datasetImportJob\"]\n",
    "    print(dataset_import_job)\n",
    "    if \"latestDatasetImportJobRun\" not in dataset_import_job:\n",
    "        status = dataset_import_job[\"status\"]\n",
    "        print(\"DatasetImportJob: {}\".format(status))\n",
    "    else:\n",
    "        status = dataset_import_job[\"latestDatasetImportJobRun\"][\"status\"]\n",
    "        print(\"LatestDatasetImportJobRun: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
